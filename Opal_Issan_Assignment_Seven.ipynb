{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoid_method(a,b,N,f):\n",
    "    Nint = int(N)\n",
    "    xvals = np.linspace(a,b,Nint+1)\n",
    "    fvals = f(xvals)\n",
    "    dx = (b-a)/N\n",
    "    return dx/2.*(fvals[0] + fvals[Nint] + 2.*np.sum(fvals[1:Nint])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_method(a,b,N,f):\n",
    "    Nint = int(N)\n",
    "    TNint = 2*N\n",
    "    xvals = np.linspace(a,b,TNint+1)\n",
    "    fvals = f(xvals)\n",
    "    dx = (b-a)/(2.*N)\n",
    "    return dx/3.*(fvals[0] + fvals[TNint] + 2.*np.sum(fvals[2:TNint-1:2]) + 4.*np.sum(fvals[1:TNint:2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: (2pts for each part) When we write \n",
    "    \n",
    "` \n",
    "xvals = np.linspace(a,b,int(n)+1)\n",
    "`\n",
    "\n",
    "we are generating a sequence of points $x_{j}$ such that \n",
    "\n",
    "$$\n",
    "\\mbox{xvals[j]} = x_{j}, ~ x_{j} = a + j\\delta x, ~ \\delta x = \\frac{b-a}{n}, ~ j=0,\\cdots,n.\n",
    "$$\n",
    "\n",
    "Thus, if I wanted to generate a sequence of points between $a=1$ and $b=9$ with spacing $\\delta x=.25$, then I would find \n",
    "\n",
    "$$\n",
    ".25 = \\frac{9-1}{n}\n",
    "$$\n",
    "\n",
    "so that $n = 32$.  I could then generate these points via the code\n",
    "\n",
    "`\n",
    "xvals = np.linspace(1.,9.,32 + 1)\n",
    "`\n",
    "\n",
    "Using the model, write the code which will generate\n",
    "\n",
    "1a) A sequence of points between $a=0$ and $b=10$ with spacing $\\delta x = 10^{-3}$.\n",
    "\n",
    "1b) A sequence of points between $a=2$ and $b=18$ with spacing $\\delta x = 2^{-m}$, where $m$ is a positive integer that a user would specify.  \n",
    "\n",
    "1c) From problem 1a, using array slicing, what code would I write to find the points $x_{j}$ such that $1\\leq x_{j} \\leq 9$?  Your answer should be in the form `xvals[n1:n2]` where `n1` and `n2` are two integers you must find.  \n",
    "\n",
    "1d) From problem 1b, using array slicing, what code would I write to find the points $x_{j}$ such that $6\\leq x_{j} \\leq 10$?  Your answer should be in the form `xvals[n1:n2]` where `n1` and `n2` are two integers you must find, though they will be in terms of $m$.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(a)\n",
    "$$\n",
    "10^{-3} = \\frac{(10-0)}{n}\\\\ \n",
    "n10^{-3} = 10\\\\\n",
    "n = 10^{4}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000e+00 1.000e-03 2.000e-03 ... 9.998e+00 9.999e+00 1.000e+01]\n"
     ]
    }
   ],
   "source": [
    "#1(a)\n",
    "print(np.linspace(0.,10., int(10**4)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b)\n",
    "$$\n",
    "2^{-m} = \\frac{18-2}{n}\\\\\n",
    "2^{-m}n = 16\\\\\n",
    "n = 16*2^{m}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1(b)\n",
    "def seqint(m):\n",
    "    n = 16.*(2.**m)\n",
    "    return np.linspace(2., 18., int(n)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.   7.5  8.   8.5\n",
      "  9.   9.5 10.  10.5 11.  11.5 12.  12.5 13.  13.5 14.  14.5 15.  15.5\n",
      " 16.  16.5 17.  17.5 18. ]\n",
      "[ 2.    2.25  2.5   2.75  3.    3.25  3.5   3.75  4.    4.25  4.5   4.75\n",
      "  5.    5.25  5.5   5.75  6.    6.25  6.5   6.75  7.    7.25  7.5   7.75\n",
      "  8.    8.25  8.5   8.75  9.    9.25  9.5   9.75 10.   10.25 10.5  10.75\n",
      " 11.   11.25 11.5  11.75 12.   12.25 12.5  12.75 13.   13.25 13.5  13.75\n",
      " 14.   14.25 14.5  14.75 15.   15.25 15.5  15.75 16.   16.25 16.5  16.75\n",
      " 17.   17.25 17.5  17.75 18.  ]\n"
     ]
    }
   ],
   "source": [
    "print(seqint(0)) #spacing of 2^0 = 1\n",
    "print(seqint(1)) #spacing of 2^-1 = 0.5\n",
    "print(seqint(2)) #spacing of 2^-2 = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "0 + 10^{-3}n1 = 1\\\\\n",
    "n1 = \\frac{1}{10^{-3}}\\\\\n",
    "0 + 10^{-3}n2 = 9 \\\\\n",
    "n2 = \\frac{9}{10^{-3}}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.    1.001 1.002 ... 8.998 8.999 9.   ]\n"
     ]
    }
   ],
   "source": [
    "#1(c)\n",
    "xvals = np.linspace(0.,10., int(1e4)+1) #from 1(a)\n",
    "dx = 10**-3.\n",
    "n1 = (1.)/dx\n",
    "n2 = (9.)/dx\n",
    "print(xvals[int(n1):int(n2)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "2+ 2^{-m}n1 = 6\\\\\n",
    "2^{-m}n1 = 4\\\\\n",
    "n1 = \\frac{4}{2^{-m}}\\\\\n",
    "$$\n",
    "and \n",
    "$$\n",
    "2+ 2^{-m}n2 = 10\\\\\n",
    "2^{-m}n2 = 8 \\\\\n",
    "n2 = \\frac{8}{2^{-m}}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1(d)\n",
    "def seq1d(m):\n",
    "    n = 16.*(2.**m)\n",
    "    xvals = np.linspace(2., 18., int(n)+1) \n",
    "    dx = 2.**(-m)\n",
    "    n1 = 4./dx \n",
    "    n2 = 8./dx\n",
    "    return xvals[int(n1): int(n2)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  7.  8.  9. 10.]\n",
      "[ 6.     6.125  6.25   6.375  6.5    6.625  6.75   6.875  7.     7.125\n",
      "  7.25   7.375  7.5    7.625  7.75   7.875  8.     8.125  8.25   8.375\n",
      "  8.5    8.625  8.75   8.875  9.     9.125  9.25   9.375  9.5    9.625\n",
      "  9.75   9.875 10.   ]\n"
     ]
    }
   ],
   "source": [
    "#1(d) testing\n",
    "print(seq1d(0))\n",
    "print(seq1d(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: (10 pts) A particle of mass $m$ moving through a fluid is subjected to viscous resistance $R(v)$, where $v$ is the particle's velocity.  Suppose that relationship between the resistance $R$, velocity $v$, and the time of travel is given by \n",
    "$$\n",
    "t = \\int_{v_{0}}^{v(t)} \\frac{m}{R(u)} du, \n",
    "$$\n",
    "where $v_{0} = v(0)$ is the intial velocity of the particle.  Now suppose that \n",
    "$$\n",
    "R(v) = -R_{\\infty}\\left(\\frac{2}{1 + e^{-v^2/v_{c}^{2}}}-1\\right).\n",
    "$$\n",
    "For a particle of mass $m=1 ~kg$ (kilograms), with $v_{0}=10 ~m/s$ (meters/second), and $v_{c} = 2 ~m/s$ and $R_{\\infty} = 3 ~kg ~m/s^{2}$, using the Trapezoid Method, find the approximate time necessary for the particle to slow to $v(t) = 5 ~ m/s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#(2)Assume \n",
    "$$\n",
    "t = \\int_{v_{0}}^{v(t)} \\frac{m}{R(u)} du\n",
    "$$\n",
    "and \n",
    "$$\n",
    "R(v) = -R_{\\infty}\\left(\\frac{2}{1 + e^{-v^2/v_{c}^{2}}}-1\\right).\n",
    "$$\n",
    "Hence, \n",
    "$$\n",
    "t = \\int_{v_{0}}^{v(t)} \\frac{m}{-R_{\\infty}\\left(\\frac{2}{1 + e^{-u^2/v_{c}^{2}}}-1\\right).} du\n",
    "$$\n",
    "It is given in the problem that \n",
    "For a particle of mass $m=1 ~kg$ (kilograms), with $v_{0}=10 ~m/s$ (meters/second), and $v_{c} = 2 ~m/s$ and $R_{\\infty} = 3 ~kg ~m/s^{2}$, using the Trapezoid Method, find the approximate time necessary for the particle to slow to $v(t) = 5 ~ m/s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)\n",
    "m= 1.\n",
    "v0= 10.\n",
    "vc= 2.\n",
    "Rinf = 3.\n",
    "vt =5.\n",
    "e = np.exp(1)\n",
    "def Rv_fun(v):\n",
    "    frac = (2.)/(1 + (e**((-1.*(v**2.))/(vc**2))))\n",
    "    bottom = (frac -1)*(-Rinf)\n",
    "    Rv = (m/bottom)\n",
    "    return Rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it takes in secononds: 1.667148688179324\n"
     ]
    }
   ],
   "source": [
    "print(\"it takes in secononds:\", trapezoid_method(v0,vt,100,Rv_fun)) # answer is time in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3** (20 pts): In class, we showed that Simpson's method for finding the integral \n",
    "\n",
    "$$\n",
    "T_{[a,b]}(f) = \\int_{a}^{b} f(x) dx, \n",
    "$$\n",
    "\n",
    "over a mesh $\\left\\{ x_{j} \\right\\}_{j=0}^{2N}$, $x_{j} = a + j\\delta x$, $\\delta x = (b-a)/(2N)$, is found via a series of local approximations via the formula \n",
    "\n",
    "\\begin{align*}\n",
    "\\int_{a}^{b} f(x) dx = & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} f(x) dx \\\\\n",
    "\\approx & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} y_{2l+1}(x;x_{2l+1}) dx \n",
    "\\end{align*}\n",
    "\n",
    "where the approximating interpolatory polynomial $y_{2l+1}(x;x_{2l+1})$ is given by \n",
    "\n",
    "$$\n",
    "y_{2l+1}(x;x_{2l+1}) = a_{2l+1}\\left(x-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x-x_{2l+1} \\right) + c_{2l+1}.\n",
    "$$\n",
    "\n",
    "The coefficients $a_{2l+1}$, $b_{2l+1}$, and $c_{2l+1}$ are found via the _interpolation_ requirements\n",
    "\n",
    "\\begin{align*}\n",
    "y_{2l+1}(x_{2l};x_{2l+1}) = & f\\left(x_{2l}\\right) = f_{2l}\\\\\n",
    "y_{2l+1}(x_{2l+1};x_{2l+1}) = & f\\left(x_{2l+1}\\right) = f_{2l+1}\\\\\n",
    "y_{2l+1}(x_{2l+2};x_{2l+1}) = & f\\left(x_{2l+2}\\right) = f_{2l+2}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "* **Part a)** (5 pts) Using the above interpolatory requirements, show that \n",
    "$$\n",
    "a_{2l+1} = \\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right), ~ b_{2l+1} = \\frac{1}{2\\delta x}\\left(f_{2l+2}-f_{2l} \\right), ~ c_{2l+1} = f_{2l+1}\n",
    "$$\n",
    "\n",
    "* **Part b)** (5 pts) Using the Taylor series expansions\n",
    "\\begin{align*}\n",
    "f_{2l} = f\\left(x_{2l+1}-\\delta x\\right) = f_{2l+1} - f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} - \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + C_{2l+1}(\\delta x)^{4}\\\\\n",
    "f_{2l+2} = f\\left(x_{2l+1}+\\delta x\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} + \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + \\bar{C}_{2l+1}(\\delta x)^{4}\n",
    "\\end{align*}\n",
    "show that \n",
    "\\begin{multline}\n",
    "y_{2l+1}\\left(x;x_{2l+1}\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x-x_{2l+1}\\right) + \\frac{f''(x_{2l+1})}{2}\\left(x-x_{2l+1}\\right)^{2} \\\\\n",
    "+ \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right) + \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2}\n",
    "\\end{multline}\n",
    "\n",
    "* **Part c)** (5 pts) Using the Taylor series expansion\n",
    "$$\n",
    "f(x) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x - x_{2l+1} \\right) + \\frac{1}{2}f''(x_{2l+1})\\left(x - x_{2l+1} \\right)^{2} + \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3} + \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4}\n",
    "$$\n",
    "show that \n",
    "\\begin{align}\n",
    "\\int_{x_{2l}}^{x_{2l+2}} \\left(f(x) - y_{2l+1}(x;x_{2l+1}) \\right) dx = & \\left(\\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right) \\right)(\\delta x)^{5}\\\\\n",
    "= & \\hat{C}_{2l+1}\\left(\\delta x \\right)^{5},\n",
    "\\end{align}\n",
    "where we use the relabeling\n",
    "$$\n",
    "\\hat{C}_{2l+1} \\equiv \\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\n",
    "$$\n",
    "\n",
    "* **Part d)** (5 pts) Letting the global Simpson's approximation be $A_{2N}(f)$ where\n",
    "\\begin{align}\n",
    "A_{2N}(f) = & \\sum_{l=0}^{N-1} \\int_{x_{2l}}^{x_{2l+2}} y_{2l+1}(x;x_{2l+1}) dx \\\\\n",
    "= &\\frac{\\delta x}{3}\\left(f_{0} + f_{2N} + 2\\sum_{l=1}^{N-1}f_{2l} + 4\\sum_{l=0}^{N-1}f_{2l+1} \\right)\n",
    "\\end{align}\n",
    "show that \n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\frac{\\hat{C}_{M}}{2}(b-a)(\\delta x)^{4}\n",
    "$$\n",
    "where $\\hat{C}_{M}$ is the biggest of all the constants $\\hat{C}_{2l+1}$ (Note, technically we should have inequalities throughout all of this, but we are only telling a small fib...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(a)\n",
    "Let \n",
    "$$\n",
    "y_{2l+1}(x;x_{2l+1}) = a_{2l+1}\\left(x-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x-x_{2l+1} \\right) + c_{2l+1}.\n",
    "$$\n",
    "\n",
    "The coefficients $a_{2l+1}$, $b_{2l+1}$, and $c_{2l+1}$ are found via the _interpolation_ requirements\n",
    "\n",
    "\\begin{align*}\n",
    "y_{2l+1}(x_{2l};x_{2l+1}) = & f\\left(x_{2l}\\right) = f_{2l}\\\\\n",
    "y_{2l+1}(x_{2l+1};x_{2l+1}) = & f\\left(x_{2l+1}\\right) = f_{2l+1}\\\\\n",
    "y_{2l+1}(x_{2l+2};x_{2l+1}) = & f\\left(x_{2l+2}\\right) = f_{2l+2}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "So, first we can work with $y_{2l+1}(x_{2l+1};x_{2l+1})$ so, \n",
    "\n",
    "$y_{2l+1}(x_{2l+1};x_{2l+1}) = f\\left(x_{2l+1}\\right) = f_{2l+1} = a_{2l+1}\\left(x_{2l+1}-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x_{2l+1}-x_{2l+1} \\right) + c_{2l+1}\n",
    "$\n",
    "Hence, $ c_{2l+1} = f_{2l+1}$\n",
    "Now, we have 2 equations with 2 unknowns:\n",
    "$$\n",
    "f_{2l} = a_{2l+1}\\left(x_{2l}-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x_{2l}-x_{2l+1} \\right) + f_{2l+1}\\\\\n",
    "f_{2l+2} =a_{2l+1}\\left(x_{2l+2}-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x_{2l+2}-x_{2l+1} \\right) + f_{2l+1}\\\\\n",
    "f_{2l} = a_{2l+1}(-\\delta x)^{2} + b_{2l+1}( -\\delta x) + f_{2l+1}\\\\\n",
    "f_{2l+2} =a_{2l+1}(\\delta x)^{2} + b_{2l+1}(\\delta x) + f_{2l+1}\\\\\n",
    "-f_{2l} + a_{2l+1}(-\\delta x)^{2} +f_{2l+1} =  b_{2l+1}( \\delta x) \\\\\n",
    "f_{2l+2} =a_{2l+1}(\\delta x)^{2} + -f_{2l} + a_{2l+1}(-\\delta x)^{2} +f_{2l+1}+ f_{2l+1}\\\\\n",
    "f_{2l+2} +f_{2l} -2f_{2l+1} = 2a_{2l+1}(\\delta x)^{2}\\\\\n",
    "a_{2l+1} = \\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right)\\\\\n",
    "b_{2l+1}( \\delta x)  = -f_{2l} + a_{2l+1}(-\\delta x)^{2} +f_{2l+1} = -f_{2l} + (\\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right))(-\\delta x)^{2} +f_{2l+1} \\\\\n",
    "b_{2l+1} = \\frac{1}{2\\delta x}\\left(f_{2l+2}-f_{2l} \\right)\\\\\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(b) Let \n",
    "\\begin{align*}\n",
    "f_{2l} = f\\left(x_{2l+1}-\\delta x\\right) = f_{2l+1} - f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} - \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + C_{2l+1}(\\delta x)^{4}\\\\\n",
    "f_{2l+2} = f\\left(x_{2l+1}+\\delta x\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} + \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + \\bar{C}_{2l+1}(\\delta x)^{4}\n",
    "\\end{align*}\n",
    "\n",
    "We know from 1(a) that \n",
    "$$\n",
    "y_{2l+1}(x;x_{2l+1}) = a_{2l+1}\\left(x-x_{2l+1} \\right)^{2} + b_{2l+1}\\left(x-x_{2l+1} \\right) + c_{2l+1}.\\\\\n",
    "a_{2l+1} = \\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right)\\\\\n",
    "b_{2l+1} = \\frac{1}{2\\delta x}\\left(f_{2l+2}-f_{2l} \\right)\\\\\n",
    "c_{2l+1} = f_{2l+1}\n",
    "$$\n",
    "So,\n",
    "$$\n",
    "y_{2l+1}(x;x_{2l+1}) = (\\frac{1}{2(\\delta x)^{2}}\\left(f_{2l} -2f_{2l+1} + f_{2l+2} \\right))\\left(x-x_{2l+1} \\right)^{2} + (\\frac{1}{2\\delta x}\\left(f_{2l+2}-f_{2l} \\right))\\left(x-x_{2l+1} \\right) + f_{2l+1}.\n",
    "$$\n",
    "Now, lets plug in what we know from the given above, \n",
    "$$y_{2l+1}(x;x_{2l+1}) = (\\frac{1}{2(\\delta x)^{2}}\\left(f\\left(x_{2l+1}-\\delta x\\right) = f_{2l+1} - f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} - \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + C_{2l+1}(\\delta x)^{4} -2f_{2l+1} + f\\left(x_{2l+1}+\\delta x\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} + \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + \\bar{C}_{2l+1}(\\delta x)^{4} \\right))\\left(x-x_{2l+1} \\right)^{2} + (\\frac{1}{2\\delta x}\\left(f\\left(x_{2l+1}+\\delta x\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} + \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + \\bar{C}_{2l+1}(\\delta x)^{4}-f\\left(x_{2l+1}-\\delta x\\right) = f_{2l+1} - f'\\left(x_{2l+1}\\right)\\delta x + \\frac{1}{2}f''\\left(x_{2l+1}\\right)(\\delta x)^{2} - \\frac{1}{6}f'''\\left(x_{2l+1}\\right)(\\delta x)^{3} + C_{2l+1}(\\delta x)^{4} \\right))\\left(x-x_{2l+1} \\right) + f_{2l+1}.\n",
    "$$\n",
    "\\begin{multline}\n",
    "y_{2l+1}\\left(x;x_{2l+1}\\right) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x-x_{2l+1}\\right) + \\frac{f''(x_{2l+1})}{2}\\left(x-x_{2l+1}\\right)^{2} \\\\\n",
    "+ \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right) + \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2}\n",
    "\\end{multline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(c)\n",
    "$$\n",
    "f(x) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x - x_{2l+1} \\right) + \\frac{1}{2}f''(x_{2l+1})\\left(x - x_{2l+1} \\right)^{2} + \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3} + \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4}\n",
    "$$\n",
    "So we have, \n",
    "$$\n",
    "f(x) - y_{2l+1}(x;x_{2l+1}) = f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x - x_{2l+1} \\right) + \\frac{1}{2}f''(x_{2l+1})\\left(x - x_{2l+1} \\right)^{2} + \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3} + \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4} - (f_{2l+1} + f'\\left(x_{2l+1}\\right)\\left(x-x_{2l+1}\\right) + \\frac{f''(x_{2l+1})}{2}\\left(x-x_{2l+1}\\right)^{2} \\\\\n",
    "+ \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right) + \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2})\n",
    "$$\n",
    "Then, by simplifying and cancelations we get:\n",
    "$$\n",
    "f(x) - y_{2l+1}(x;x_{2l+1}) = \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3} + \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4} - \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right) - \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2})\n",
    "$$\n",
    "relabel:\n",
    "$$\n",
    "A1 = \\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{3}\\\\\n",
    "B1 = \\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{4}\\\\\n",
    "C1 = \\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right)\\\\\n",
    "D1 = \\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{2})\\\\\n",
    "$$\n",
    "Hence, $f(x) - y_{2l+1}(x;x_{2l+1}) = A1+B1-C1-D1$\n",
    "So, \n",
    "$$\n",
    "\\int_{}^{} A1 = 1/4\\frac{1}{6}f'''(x_{2l+1})(x-x_{2l+1})^{4} + C1\\\\\n",
    "\\int_{}^{} B1 = 1/5\\tilde{C}_{2l+1}\\left(x-x_{2l+1}\\right)^{5} +C2\\\\\n",
    "\\int_{}^{} C1 = 1/2\\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x-x_{2l+1}\\right)^{2} +C3\\\\\n",
    "\\int_{}^{} D1 =1/3\\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x-x_{2l+1}\\right)^{3})+C4\n",
    "\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "$$\n",
    "$$\n",
    "\\int_{x_{2l}}^{x_{2l+2}} A1 = 1/4\\frac{1}{6}f'''(x_{2l+1})(x_{2l+2}-x_{2l+1})^{4}- 1/4\\frac{1}{6}f'''(x_{2l+1})(x_{2l}-x_{2l+1})^{4} = 1/4\\frac{1}{6}f'''(x_{2l+1})(\\delta x)^{4}- 1/4\\frac{1}{6}f'''(x_{2l+1})(\\delta x)^{4} = 0.\\\\\n",
    "\\int_{x_{2l}}^{x_{2l+2}} B1 =1/5\\tilde{C}_{2l+1}\\left(x_{2l+2}-x_{2l+1}\\right)^{5} - 1/5\\tilde{C}_{2l+1}\\left(x_{2l}-x_{2l+1}\\right)^{5} = 2/5\\tilde{C}_{2l+1}(\\delta x)^{5}\\\\\n",
    "\\int_{x_{2l}}^{x_{2l+2}} C1 =1/2\\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x_{2l+2}-x_{2l+1}\\right)^{2} -1/2\\frac{(\\delta x)^{2}}{2}\\left(\\frac{1}{3}f'''\\left(x_{2l+1}\\right) + \\left(\\bar{C}_{2l+1}-C_{2l+1}\\right)\\delta x\\right)\\left(x_{2l}-x_{2l+1}\\right)^{2} = 0\\\\\n",
    "\\int_{x_{2l}}^{x_{2l+2}} D1 =1/3\\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x_{2l+2}-x_{2l+1}\\right)^{3}) -1/3\\frac{1}{2}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{2}\\left(x_{2l}-x_{2l+1}\\right)^{3}) = \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\\left(\\delta x\\right)^{5}\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int_{x_{2l}}^{x_{2l+2}} \\left(f(x) - y_{2l+1}(x;x_{2l+1}) \\right) dx = \\int_{x_{2l}}^{x_{2l+2}} A1 + \\int_{x_{2l}}^{x_{2l+2}} B1 - \\int_{x_{2l}}^{x_{2l+2}} C1 - \\int_{x_{2l}}^{x_{2l+2}} D1\n",
    "$$\n",
    "Finally we can conclude that, \n",
    "\\begin{align}\n",
    "\\int_{x_{2l}}^{x_{2l+2}} \\left(f(x) - y_{2l+1}(x;x_{2l+1}) \\right) dx = & \\left(\\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right) \\right)(\\delta x)^{5}\\\\\n",
    "= & \\hat{C}_{2l+1}\\left(\\delta x \\right)^{5},\n",
    "\\end{align}\n",
    "where we use the relabeling\n",
    "$$\n",
    "\\hat{C}_{2l+1} \\equiv \\frac{2}{5}\\tilde{C}_{2l+1} - \\frac{1}{3}\\left(C_{2l+1}+\\bar{C}_{2l+1}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(d)\n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\sum_{l=0}^{N-1}\\int_{x_{2l}}^{x_{2l+2}} \\left(f(x) - y_{2l+1}(x;x_{2l+1}) \\right) dx\n",
    "$$\n",
    "from part c we showed that:\n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\sum_{l=0}^{N-1} \\hat{C}_{2l+1}\\left(\\delta x \\right)^{5} = \\left(\\delta x \\right)^{5} \\sum_{l=0}^{N-1} \\hat{C}_{2l+1} = \\hat{C}_{M}\\left(\\delta x \\right)^{5} \\sum_{l=0}^{N-1} 1 = \\hat{C}_{M}\\left(\\delta x \\right)^{5} N \n",
    "$$\n",
    "where $\\hat{C}_{M}$ is the biggest of all the constants $\\hat{C}_{2l+1}$ (Note, technically we should have inequalities throughout all of this, but we are only telling a small fib...)\n",
    "where $\\delta x = \\frac{b-a}{2N}$.\n",
    "So,\n",
    "$ N = \\frac{(b-a)}{2\\delta x}$\n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\hat{C}_{M}(\\delta x)^{5}N= \\hat{C}_{M}\\frac{b-a}{2}(\\delta x)^{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4** (10 pts): Choose an example and using the code from Lecture 5 as a model, numerically verify the error analysis we performed for Simpson's method above by generating a log/log plot and a corresponding estimate of the slope of the plotted line.  Note, you may have to use clever choices for $N$ or slicing choices in order to remove nan terms and the like from your slope estimates.  Provide a brief summary of your results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(xvals):\n",
    "    return xvals**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpson_method(a,b,N,f):\n",
    "    xvals = np.linspace(a,b,int(N)+1)\n",
    "    fvals = f(xvals)\n",
    "    dx = (b-a)/int(N)\n",
    "    return dx/3.*(fvals[0] + fvals[int(N)] + 2.*np.sum(fvals[2:(int(N)-1):2])+4.*np.sum(fvals[1:int(N):2]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_test(a,b,f):\n",
    "    tval =  (b**5.)/5. -(a**5.)/5.\n",
    "    Nvals = np.array([1e2, 1e3, 1e4])\n",
    "    Evals = np.zeros(Nvals.size)\n",
    "    for jj in range(0,Nvals.size):\n",
    "        Evals[jj] = np.log10(np.abs(tval - simpson_method(a,b,Nvals[jj],f)))\n",
    "    xvals = np.log10(Nvals)\n",
    "    plt.plot(xvals,Evals)\n",
    "    plt.xlabel('$log_{10}|\\delta x|$')\n",
    "    plt.ylabel('$log_{10}|error|$')\n",
    "    novals = Evals.size\n",
    "    slopes = Evals[1:] - Evals[:novals-1]\n",
    "    print(np.min(slopes))\n",
    "    print(np.max(slopes))\n",
    "    print(np.mean(slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.000033702041067\n",
      "-3.4980347236870273\n",
      "-3.7490342128640473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_test(0.,0.2,test_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part problem 3 part d,  I showed that \n",
    "$$\n",
    "T_{[a,b]}(f) - A_{2N}(f) = \\hat{C}_{M}(\\delta x)^{5}N= \\hat{C}_{M}\\frac{b-a}{2}(\\delta x)^{4}\n",
    "$$\n",
    "Hence, \n",
    "$$\n",
    "Error = \\hat{C}_{M}\\frac{b-a}{2}(\\delta x)^{4}\\\\\n",
    "log_{10}|Error| = log_{10}(\\hat{C}_{M}\\frac{b-a}{2}(\\delta x)^{4})\\\\\n",
    "log_{10}|Error| = log_{10}(\\hat{C}_{M}\\frac{b-a}{2}) + log_{10}(\\delta x)^{4}\\\\\n",
    "log_{10}|Error| = log_{10}(\\hat{C}_{M}\\frac{b-a}{2}) + 4*log_{10}(\\delta x)\n",
    "$$\n",
    "In the graph above, y axis represtents $log_{10}|Error|$ and the x axis is $ log_{10}(\\delta x)$ so the slope is 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
