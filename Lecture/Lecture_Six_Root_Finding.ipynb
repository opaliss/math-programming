{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Finding\n",
    "\n",
    "The point of this section is pretty straightforward.  I give you a function $f(x)$ and an interval, say $[a,b]$.  Now you tell me those points $c_{\\ast}\\in[a,b]$ such that \n",
    "\n",
    "$$\n",
    "f(c_{\\ast}) = 0.\n",
    "$$\n",
    "\n",
    "The first approach we are going to study is called the _ Bisection Method _.  It relies on there being a sign change over the interval $[a,b]$.  Said another way, for the Bisection Method to work we need\n",
    "\n",
    "> **Criteria for Bisection Method**: For the Bisection method to work on an interval $[a,b]$, we need $f$ to be continuous on $[a,b]$, and we need $f(a)f(b)<0$.\n",
    "\n",
    "The sign change ensures that there is some point $c \\in (a,b)$ such that $f(c)=0$. Once we know the criteria is met, the method goes as follows.  \n",
    "\n",
    "1.  Find the mid-point $c = \\frac{b+a}{2}$. \n",
    "2.  Check $f(c)=0$.  If yes, you have a root.  \n",
    "3.  If not, check $f(a)f(c)<0$.  If yes, you have a root in $(a,c)$.  If not, you have a root in $(c,b)$.\n",
    "4.  Re-define your interval accordingly, repeat until... well what makes sense here?\n",
    "\n",
    "![bsctmeth](https://upload.wikimedia.org/wikipedia/commons/8/8c/Bisection_method.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisec_method(a,b,f,tol):\n",
    "    fa,fb = f(a),f(b)\n",
    "    if #you put code here:\n",
    "        c = #you put code here\n",
    "        capproxs = np.array([c]) # build an array to record the estimates we make for the root\n",
    "        fc = f(c)\n",
    "        while #and you put a whole lot of code here:\n",
    "            if :\n",
    "                #    \n",
    "            else:\n",
    "                #    \n",
    "                #    \n",
    "            #\n",
    "            capproxs = np.append(capproxs,c)\n",
    "            \n",
    "        print \"Our root is: %1.15f\" %c\n",
    "    else:\n",
    "        print \"Cannot ensure existence of root.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 + 3.*x**2 - 2.*x - 1.\n",
    "xvals = np.linspace(-5.,3.,int(1e3))\n",
    "yvals = f(xvals)\n",
    "zvals = np.zeros(xvals.size)\n",
    "plt.plot(xvals,yvals,color='b')\n",
    "plt.plot(xvals,zvals,color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisec_method(-5.,3.,f,1e-13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate of Convergence\n",
    "\n",
    "We now want a means of figuring out how fast the Bisection Method runs.  So, if you think about it, at every iteration of the method, an approximation, say $c_{n}$, to the root, say $c_{\\ast}$, is generated.  For the method to converge, we mean that \n",
    "\n",
    "$$\n",
    "\\lim_{n\\rightarrow \\infty} c_{n} = c_{\\ast},\n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$\n",
    "\\lim_{n\\rightarrow \\infty} \\left|c_{n} - c_{\\ast}\\right|=0,\n",
    "$$\n",
    "\n",
    "But the question then becomes, how quickly does this limit go to zero?  \n",
    "\n",
    "_Problem_: Can you do this for the Bisection Method?  In other words, is there a formula you can write down which tells you how quickly $|c_{n}-c_{\\ast}|$ goes to zero?\n",
    "\n",
    "In general, we think of answering this question by defining what is called the rate of convergence.\n",
    "\n",
    "> **Rate of Convergence**: For an iterative sequence $c_{n}\\rightarrow c_{\\ast}$, we define the rate of convergence, $\\alpha$, to be $$\\lim_{n\\rightarrow\\infty}\\frac{\\left|c_{n+1}-c_{\\ast}\\right|}{\\left|c_{n}-c_{\\ast}\\right|^{\\alpha}} = \\lambda $$.\n",
    "\n",
    "The idea here is that for very large $n$, we have that \n",
    "\n",
    "$$\n",
    "\\left|c_{n+1}-c_{\\ast}\\right| \\approx \\lambda \\left|c_{n}-c_{\\ast}\\right|^{\\alpha}\n",
    "$$\n",
    "\n",
    "_Problem_: What would a logarithm tell you?  How would you use that to numerically compute the rate of convergence?  \n",
    "\n",
    "_Problem_: Modify your code for the Bisection Method to find the rate of convergence.  Does it agree with your theoretical prediction?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Newton's Method\n",
    "\n",
    "The idea here is to use the tangent line approximation of a function, say $f(x)$, to approximate a root.  By this we mean, at the point $(x,f(x))$, finding a root $x_{\\ast}$ by solving \n",
    "\n",
    "$$\n",
    "0 = f(x) + f'(x)(x_{\\ast}-x),\n",
    "$$\n",
    "which upon solving for the root $x_{\\ast}$, gives us \n",
    "\n",
    "$$\n",
    "x_{\\ast} = x - \\frac{f(x)}{f'(x)}.\n",
    "$$\n",
    "\n",
    "However, we imagine this only works if $x$ is very close to $x_{ast}$.  However, if that is the case, then if we turn this in to an interative method via the formula,\n",
    "\n",
    "$$\n",
    "x_{n} = x_{n-1} - \\frac{f(x_{n-1})}{f'(x_{n-1})}, ~ n\\geq 1\n",
    "$$\n",
    "\n",
    "then by repeating this process again and again, we should get closer and closer to the actual root.  \n",
    "\n",
    "![nwtmeth](https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif)\n",
    "_ Problem _: You code this up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: x**3. + 3.*x**2. - 2.*x - 1\n",
    "fp = lambda x: 3.*x**2. + 6.*x - 2.\n",
    "\n",
    "def Newtons_method(f,fp,x0,tol):\n",
    "    xapprox = np.array([x0,x1])\n",
    "    while np.abs(x1-x0):\n",
    "        xapprox = np.append(xapprox,x1)\n",
    "    #conv_plotter(xapprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Newtons_method(f,fp,-3.,1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Secant Method\n",
    "\n",
    "We note that Newton's method suffers from a couple of flaws.  First, it will not work if $f'(x_{\\ast})=0$.  Further, if $\\left|f'(x_{\\ast})\\right|\\ll 1$, it will work very, very slowly.  Further, we also note that the method requires us to compute a derivative of what could be very complicated functions.  Thus, it turns out that by using an approximation to the derivative of the form\n",
    "\n",
    "$$\n",
    "f'(x_{n}) \\approx \\frac{f(x_{n})-f(x_{n-1})}{x_{n}-x_{n-1}},\n",
    "$$\n",
    "\n",
    "we can partially get around some of these problems.  This approach is called the _ Secant Method _.  See if you can code it up.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_plotter_mod(cvals):\n",
    "    clen = cvals.size\n",
    "    cstr = cvals[clen-1]\n",
    "    xvals = np.ma.log10(np.abs(cvals[:clen-3] - cstr))\n",
    "    yvals = np.ma.log10(np.abs(cvals[1:clen-2] - cstr))\n",
    "    ylen = yvals.size\n",
    "    plt.plot(xvals,yvals)\n",
    "    plt.scatter(xvals,yvals)\n",
    "    slopes = (yvals[1:]-yvals[:ylen-1])/(xvals[1:]-xvals[:ylen-1])\n",
    "    print np.max(slopes)\n",
    "    print np.min(slopes)\n",
    "    print np.mean(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_method_mod(f,x0,x1,tol):\n",
    "    \n",
    "    while #add code:\n",
    "    \n",
    "    return xapprox.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.pi\n",
    "xvals = np.linspace(.5,1.5,int(1e3)+1)\n",
    "zvals = np.zeros(xvals.size)\n",
    "f = lambda x: x*np.cos(x) - (np.sin(x))**2.\n",
    "fp = lambda x: np.cos(x) - x*np.sin(x) - 2*np.sin(x)*np.cos(x)\n",
    "plt.figure(1)\n",
    "plt.plot(xvals,f(xvals))\n",
    "plt.plot(xvals,zvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pows = np.arange(2,8)\n",
    "tols = 10.**(-pows)\n",
    "a = \n",
    "b = \n",
    "ind = 0\n",
    "cntbsc = np.zeros(tols.size)\n",
    "cntscnt = np.zeros(tols.size)\n",
    "cntnwt = np.zeros(tols.size)\n",
    "for tol in tols:\n",
    "    cntbsc[ind] = \n",
    "    cntscnt[ind] = \n",
    "    cntnwt[ind] = \n",
    "    ind += 1\n",
    "    \n",
    "plt.plot(pows,cntbsc,color='r',label=\"Bisection\")\n",
    "plt.plot(pows,cntscnt,color='k',label=\"Secant\")\n",
    "plt.plot(pows,cntnwt,color='b',label=\"Newton\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Tolerance\")\n",
    "plt.ylabel(\"Iteration Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
